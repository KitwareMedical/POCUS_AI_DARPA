{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2108fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChannel,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    EnsureChannelFirst,\n",
    "    EnsureType,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandSpatialCrop,\n",
    "    RandZoom,\n",
    "    ScaleIntensityRange,\n",
    "    SpatialCrop,\n",
    "    ToTensor,\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import decollate_batch\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import site\n",
    "site.addsitedir('../../ARGUS')\n",
    "from ARGUSUtils_Transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dd296a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    }
   ],
   "source": [
    "img1_dir = \"../../Data/VFoldData/ColumnData/\"\n",
    "\n",
    "all_images = sorted(glob(os.path.join(img1_dir, '*_Class?_*.mha')))\n",
    "\n",
    "num_folds = 10\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "num_workers_tr = 8\n",
    "batch_size_tr = 8\n",
    "num_workers_va = 8\n",
    "batch_size_va = 2\n",
    "\n",
    "model_filename_base = \"BAMC_PTX_3DUNet-4Class.best_model.vfold64-Columns-Class\"\n",
    "\n",
    "num_images = len(all_images)\n",
    "print(num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4c16aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163 26 15\n",
      "167 15 22\n",
      "164 22 18\n",
      "167 18 19\n",
      "171 19 14\n",
      "168 14 22\n",
      "163 22 19\n",
      "164 19 21\n",
      "155 21 28\n",
      "150 28 26\n"
     ]
    }
   ],
   "source": [
    "ns_prefix = ['025ns','026ns','027ns','035ns','048ns','055ns','117ns',\n",
    "             '135ns','193ns','210ns','215ns','218ns','219ns','221ns','247ns']\n",
    "s_prefix = ['004s','019s','030s','034s','037s','043s','065s','081s',\n",
    "            '206s','208s','211s','212s','224s','228s','236s','237s']\n",
    "\n",
    "fold_prefix_list = []\n",
    "ns_count = 0\n",
    "s_count = 0\n",
    "for i in range(num_folds):\n",
    "    if i%2 == 0:\n",
    "        num_ns = 2\n",
    "        num_s = 1\n",
    "        if i > num_folds-3:\n",
    "            num_s = 2\n",
    "    else:\n",
    "        num_ns = 1\n",
    "        num_s = 2\n",
    "    f = []\n",
    "    for ns in range(num_ns):\n",
    "        f.append([ns_prefix[ns_count+ns]])\n",
    "    ns_count += num_ns\n",
    "    for s in range(num_s):\n",
    "        f.append([s_prefix[s_count+s]])\n",
    "    s_count += num_s\n",
    "    fold_prefix_list.append(f)\n",
    "        \n",
    "train_files = []\n",
    "train_classes = []\n",
    "val_files = []\n",
    "val_classes = []\n",
    "test_files = []\n",
    "test_classes = []\n",
    "\n",
    "for i in range(num_folds):\n",
    "    tr_folds = []\n",
    "    for f in range(i,i+num_folds-2):\n",
    "        tr_folds.append(fold_prefix_list[f%num_folds])\n",
    "    tr_folds = list(np.concatenate(tr_folds).flat)\n",
    "    va_folds = list(np.concatenate(fold_prefix_list[(i+num_folds-2) % num_folds]).flat)\n",
    "    te_folds = list(np.concatenate(fold_prefix_list[(i+num_folds-1) % num_folds]).flat)\n",
    "\n",
    "    train_files.append([im for im in all_images if any(pref in im for pref in tr_folds)])\n",
    "    fold_classes = []\n",
    "    for file in train_files[len(train_files)-1]:\n",
    "        if 'ClassN' in file:\n",
    "            fold_classes.append(0)\n",
    "        elif 'ClassR' in file:\n",
    "            fold_classes.append(1)\n",
    "        elif 'ClassS' in file:\n",
    "            fold_classes.append(2)\n",
    "        else:\n",
    "            print(\"Error: Class tag not found in validation file\", file)\n",
    "    train_classes.append(fold_classes)\n",
    "\n",
    "    val_files.append([im for im in all_images if any(pref in im for pref in va_folds)])\n",
    "    fold_classes = []\n",
    "    for file in val_files[len(val_files)-1]:\n",
    "        if 'ClassN' in file:\n",
    "            fold_classes.append(0)\n",
    "        elif 'ClassR' in file:\n",
    "            fold_classes.append(1)\n",
    "        elif 'ClassS' in file:\n",
    "            fold_classes.append(2)\n",
    "        else:\n",
    "            print(\"Error: Class tag not found in validation file\", file)\n",
    "    val_classes.append(fold_classes)\n",
    "\n",
    "    test_files.append([im for im in all_images if any(pref in im for pref in te_folds)])\n",
    "    fold_classes = []\n",
    "    for file in test_files[len(test_files)-1]:\n",
    "        if 'ClassN' in file:\n",
    "            fold_classes.append(0)\n",
    "        elif 'ClassR' in file:\n",
    "            fold_classes.append(1)\n",
    "        elif 'ClassS' in file:\n",
    "            fold_classes.append(2)\n",
    "        else:\n",
    "            print(\"Error: Class tag not found in validation file\", file)\n",
    "    test_classes.append(fold_classes)\n",
    "\n",
    "    print(len(train_files[i]),len(val_files[i]),len(test_files[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d9e0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True),\n",
    "        AddChannel(),\n",
    "        ScaleIntensityRange(\n",
    "            a_min=0, a_max=255,\n",
    "            b_min=0.0, b_max=1.0),\n",
    "        ARGUS_RandSpatialCropSlices(\n",
    "            num_slices=48,\n",
    "            axis=2),\n",
    "        ARGUS_RandSpatialCropSlices(\n",
    "            num_slices=8,\n",
    "            axis=0,\n",
    "            require_labeled=True),\n",
    "        RandFlip(\n",
    "            prob=0.5, \n",
    "            spatial_axis=2),\n",
    "        RandFlip(\n",
    "            prob=0.5, \n",
    "            spatial_axis=0),\n",
    "        RandZoom(\n",
    "            prob=0.5, \n",
    "            min_zoom=1.0,\n",
    "            max_zoom=1.2,\n",
    "            keep_size=True,\n",
    "            mode='trilinear'),\n",
    "        ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True),\n",
    "        AddChannel(),\n",
    "        ScaleIntensityRange(\n",
    "            a_min=0, a_max=255,\n",
    "            b_min=0.0, b_max=1.0),\n",
    "        ARGUS_RandSpatialCropSlices(\n",
    "            num_slices=48,\n",
    "            axis=2),\n",
    "        ARGUS_RandSpatialCropSlices(\n",
    "            num_slices=8,\n",
    "            axis=0,\n",
    "            require_labeled=True),\n",
    "        ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "y_pred_trans = Compose([EnsureType(), Activations(softmax=True)])\n",
    "y_trans = Compose([EnsureType(), AsDiscrete(to_onehot=True, num_classes=num_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa31a45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 163 163\n",
      "10 26 26\n"
     ]
    }
   ],
   "source": [
    "class ColumnDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "print(str(num_folds), len(train_files[0]), len(train_classes[0]))\n",
    "train_ds = [ColumnDataset(train_files[i], train_classes[i], transforms=train_transforms)\n",
    "                for i in range(num_folds)]\n",
    "train_loader = [torch.utils.data.DataLoader(train_ds[i], batch_size=batch_size_tr, shuffle=True)\n",
    "                for i in range(num_folds)]\n",
    "\n",
    "print(str(num_folds), len(val_files[0]), len(val_classes[0]))\n",
    "val_ds = [ColumnDataset(val_files[i], val_classes[i], transforms=val_transforms)\n",
    "                for i in range(num_folds)]\n",
    "val_loader = [torch.utils.data.DataLoader(val_ds[i], batch_size=batch_size_va, shuffle=True)\n",
    "                for i in range(num_folds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5edcca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from collections import OrderedDict\n",
    "\n",
    "device = torch.device(\"cuda3\")\n",
    "\n",
    "def vfold_train(vfold_num, train_loader, val_loader):\n",
    "    model = torchvision.models.vgg16(pretrained = True).to(device)\n",
    "        \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    layers_vgg16 = torch.nn.Sequential(OrderedDict([\n",
    "                    ('fc1', nn.Linear(25088, 512)),\n",
    "                    ('activation1', nn.ReLU()),\n",
    "                    ('dropout1', nn.Dropout()),\n",
    "                    ('fc2', nn.Linear(512, 256)),\n",
    "                    ('activation2', nn.ReLU()),\n",
    "                    ('dropout2', nn.Dropout()),\n",
    "                    ('fc3', nn.Linear(256, 128)),\n",
    "                    ('activation3', nn.ReLU()),\n",
    "                    ('dropout3', nn.Dropout()),\n",
    "                    ('fc4', nn.Linear(128, 1)),\n",
    "                    ('out', nn.Sigmoid())])).to(device)\n",
    "\n",
    "    model.classifier = layers_vgg16 #or _vgg19, or _resnet34\n",
    "\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
    "    auc_metric = ROCAUCMetric()\n",
    "\n",
    "    max_epochs = 1000\n",
    "    val_interval = 1\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    epoch_loss_values = []\n",
    "    metric_values = []\n",
    "    \n",
    "    root_dir = \".\"\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"{vfold_num}: epoch {epoch + 1}/{max_epochs}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            inputs, labels = (\n",
    "                batch_data[0].to(device),\n",
    "                batch_data[1].to(device),\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            print(\n",
    "                f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
    "                f\"train_loss: {loss.item():.4f}\")\n",
    "        epoch_loss /= step\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        print(f\"{vfold_num} epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
    "                y = torch.tensor([], dtype=torch.long, device=device)\n",
    "                for val_data in val_loader:\n",
    "                    val_images, val_labels = (\n",
    "                        val_data[0].to(device),\n",
    "                        val_data[1].to(device),\n",
    "                    )\n",
    "                    y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
    "                    y = torch.cat([y, val_labels], dim=0)\n",
    "                y_onehot = [y_trans(i) for i in decollate_batch(y)]\n",
    "                y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred)]\n",
    "                auc_metric(y_pred_act, y_onehot)\n",
    "                result = auc_metric.aggregate()\n",
    "                auc_metric.reset()\n",
    "                del y_pred_act, y_onehot\n",
    "                metric_values.append(result)\n",
    "                acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
    "                acc_metric = acc_value.sum().item() / len(acc_value)\n",
    "                if result > best_metric:\n",
    "                    best_metric = result\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    torch.save(model.state_dict(), os.path.join(\n",
    "                        root_dir, model_filename_base+'_'+str(vfold_num)+'.pth'))\n",
    "                    print(\"saved new best metric model\")\n",
    "                print(\n",
    "                    f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                    f\" current accuracy: {acc_metric:.4f}\"\n",
    "                    f\" best AUC: {best_metric:.4f}\"\n",
    "                    f\" at epoch: {best_metric_epoch}\"\n",
    "                )\n",
    "\n",
    "    np.save(model_filename_base+\"_loss_\"+str(vfold_num)+\".npy\", epoch_loss_values)\n",
    "    np.save(model_filename_base+\"_acc_\"+str(vfold_num)+\".npy\", metric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12667a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "0: epoch 1/1000\n",
      "140\n",
      "61\n",
      "113\n",
      "2\n",
      "85\n",
      "157\n",
      "127\n",
      "13\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input image (T: 1 H: 40 W: 6) smaller than kernel size (kT: 2 kH: 2 kW: 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13503/2060730748.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mvfold_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_13503/1022747736.py\u001b[0m in \u001b[0;36mvfold_train\u001b[0;34m(vfold_num, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     28\u001b[0m             )\n\u001b[1;32m     29\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/monai/networks/nets/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m         return F.avg_pool3d(input, self.kernel_size, self.stride,\n\u001b[0m\u001b[1;32m    701\u001b[0m                             self.padding, self.ceil_mode, self.count_include_pad, self.divisor_override)\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input image (T: 1 H: 40 W: 6) smaller than kernel size (kT: 2 kH: 2 kW: 2)"
     ]
    }
   ],
   "source": [
    "for i in range(0,num_folds):\n",
    "    vfold_train(i, train_loader[i], val_loader[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c589918e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Data/VFoldData/ColumnData/025ns_Image_262499828648_clean_ClassR_147-166.mha\n"
     ]
    }
   ],
   "source": [
    "print(train_files[0][13])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
