{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da748914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    AsChannelFirstd,\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    Invertd,\n",
    "    LabelFilterd,\n",
    "    Lambdad,\n",
    "    LoadImaged,\n",
    "    RandFlipd,\n",
    "    RandSpatialCropd,\n",
    "    RandZoomd,\n",
    "    Resized,\n",
    "    ScaleIntensityRanged,\n",
    "    SpatialCrop,\n",
    "    SpatialCropd,\n",
    "    ToTensord,\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import itk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import argparse\n",
    "\n",
    "import ubelt as ub\n",
    "\n",
    "import site\n",
    "site.addsitedir('../../../ARGUS')\n",
    "from ARGUS_Transforms import ARGUS_RandSpatialCropSlicesd  # NOQA\n",
    "\n",
    "import pint\n",
    "Ureg = pint.UnitRegistry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18307232",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pocus_ai_pnb_needle_network:\n",
    "    \n",
    "    def __init__(self, img_dir, anno_dir, device_num, run_id):\n",
    "        self.device_num = device_num\n",
    "        self.run_id = run_id\n",
    "        \n",
    "        self.all_images = sorted(glob(os.path.join(img_dir, '*_cropM.mha')))\n",
    "        self.all_labels = sorted(glob(os.path.join(anno_dir, '*.overlay.mha')))\n",
    "\n",
    "        total_bytes = 0\n",
    "        for p in self.all_images:\n",
    "            p = ub.Path(p)\n",
    "            total_bytes += p.stat().st_size\n",
    "        print((total_bytes * Ureg.byte).to('GiB'))\n",
    "\n",
    "        total_bytes = 0\n",
    "        for p in self.all_labels:\n",
    "            p = ub.Path(p)\n",
    "            total_bytes += p.stat().st_size\n",
    "        print((total_bytes * Ureg.byte).to('GiB'))\n",
    "\n",
    "        self.num_folds = 10\n",
    "\n",
    "        self.num_classes = 3\n",
    "\n",
    "        self.max_epochs = 1500\n",
    "\n",
    "        self.net_dims = 2 # Spatial Dimensions\n",
    "        self.net_in_channels = 6 # Mean, Std, RawFrame\n",
    "        self.net_channels=(16, 32, 64, 128, 32)\n",
    "        self.net_strides=(2, 2, 2, 2)\n",
    "\n",
    "        self.num_workers_train = 3\n",
    "        self.batch_size_train = 12\n",
    "        \n",
    "        self.num_workers_val = 1\n",
    "        self.batch_size_val = 2\n",
    "\n",
    "        self.num_slices = 16\n",
    "        self.size_x = 320\n",
    "        self.size_y = 640\n",
    "\n",
    "        #filename_base = os.path.basename(__file__)\n",
    "        filename_base = \"ARUNet-NeedleArtery-VFold-Training\"\n",
    "        self.model_filename_base = \"./Results/\"+filename_base+\"-\"+str(self.num_slices)+\"s-VFold-Run\"+str(self.run_id)\n",
    "\n",
    "        if not os.path.exists(self.model_filename_base):\n",
    "            os.makedirs(self.model_filename_base)\n",
    "        self.model_filename_base = self.model_filename_base+\"/\"\n",
    "\n",
    "    def setup_data_files(self):\n",
    "        num_images = len(self.all_images)\n",
    "        print(\"Num images / labels =\", num_images, len(self.all_labels))\n",
    "\n",
    "        # 46 ok\n",
    "        # 178 bad\n",
    "        # 207 ok\n",
    "        # 230 ok\n",
    "        # 54 ok\n",
    "        p_prefix = [' 11',\n",
    "                ' 46',\n",
    "                ' 207',\n",
    "                ' 67', \n",
    "                ' 93', \n",
    "                ' 94', \n",
    "                ' 134', \n",
    "                ' 211', \n",
    "                ' 222A',  \n",
    "                ' 153', \n",
    "                ' 240',  \n",
    "                ' 193']\n",
    "        n_prefix = [' 57',\n",
    "                ' 136', \n",
    "                ' 179', \n",
    "                ' 189', \n",
    "                ' 204', \n",
    "                ' 205', \n",
    "                ' 217', \n",
    "                ' 238',  \n",
    "                ' 39',\n",
    "                ' 230',\n",
    "                ' 54',\n",
    "                ' 191']\n",
    "\n",
    "        fold_prefix_list = []\n",
    "        p_count = 0\n",
    "        n_count = 0\n",
    "        for i in range(self.num_folds):\n",
    "            num_p = 1\n",
    "            num_n = 1\n",
    "            if i > self.num_folds-5:\n",
    "                if i%2 == 0:\n",
    "                    num_p = 2\n",
    "                    num_n = 1\n",
    "                else:\n",
    "                    num_p = 1\n",
    "                    num_n = 2\n",
    "            f = []\n",
    "            if p_count < len(p_prefix):\n",
    "                for p in range(num_p):\n",
    "                    f.append([p_prefix[p_count+p]])\n",
    "            p_count += num_p\n",
    "            if n_count < len(n_prefix):\n",
    "                for n in range(num_n):\n",
    "                    f.append([n_prefix[n_count+n]])\n",
    "            n_count += num_n\n",
    "            fold_prefix_list.append(f)\n",
    "\n",
    "        for i in range(self.num_folds):\n",
    "            print(i, fold_prefix_list[i])\n",
    "\n",
    "        self.train_files = []\n",
    "        self.val_files = []\n",
    "        self.test_files = []\n",
    "\n",
    "        for i in range(self.num_folds):\n",
    "            tr_folds = []\n",
    "            va_folds = []\n",
    "            for f in range(i,i+self.num_folds-3):\n",
    "                tr_folds.append(fold_prefix_list[f % self.num_folds])\n",
    "            tr_folds = list(np.concatenate(tr_folds).flat)\n",
    "            for f in range(i+self.num_folds-3, i+self.num_folds-1):\n",
    "                va_folds.append(fold_prefix_list[f % self.num_folds])\n",
    "            va_folds = list(np.concatenate(va_folds).flat)\n",
    "            te_folds = list(np.concatenate(\n",
    "                fold_prefix_list[(i+self.num_folds-1) % self.num_folds]).flat)\n",
    "            self.train_files.append(\n",
    "                [ {\"image\": img, \"label\": seg}\n",
    "                    for img, seg in zip(\n",
    "                        [im for im in self.all_images if\n",
    "                             any(pref in im for pref in tr_folds)],\n",
    "                        [se for se in self.all_labels if\n",
    "                             any(pref in se for pref in tr_folds)])\n",
    "                ] )\n",
    "            self.val_files.append(\n",
    "                [ {\"image\": img, \"label\": seg}\n",
    "                    for img, seg in zip(\n",
    "                        [im for im in self.all_images if\n",
    "                            any(pref in im for pref in va_folds)],\n",
    "                        [se for se in self.all_labels if\n",
    "                            any(pref in se for pref in va_folds)])\n",
    "                ] )\n",
    "            self.test_files.append(\n",
    "                [ {\"image\": img, \"label\": seg}\n",
    "                    for img, seg in zip(\n",
    "                        [im for im in self.all_images if\n",
    "                            any(pref in im for pref in te_folds)],\n",
    "                        [se for se in self.all_labels if\n",
    "                            any(pref in se for pref in te_folds)])\n",
    "                    ]\n",
    "                )\n",
    "            print(len(self.train_files[i]),len(self.val_files[i]),len(self.test_files[i]))\n",
    "\n",
    "                \n",
    "    def setup_data_transforms(self):\n",
    "        self.train_transforms = Compose(\n",
    "            [\n",
    "            LoadImaged(keys=[\"image\", \"label\"]),\n",
    "            AsChannelFirstd(keys='image'),\n",
    "            AsChannelFirstd(keys='label'),\n",
    "            ScaleIntensityRanged(\n",
    "                a_min=0, a_max=255,\n",
    "                b_min=0.0, b_max=1.0,\n",
    "                keys=[\"image\"]),\n",
    "            ARGUS_RandSpatialCropSlicesd(\n",
    "                num_slices=[self.num_slices,1],\n",
    "                axis=0,\n",
    "                reduce_to_statistics=[True,False],\n",
    "                require_labeled=True,\n",
    "                extended=False,\n",
    "                include_center_slice=True,\n",
    "                include_gradient=True,\n",
    "                keys=['image','label']),\n",
    "            Resized(\n",
    "                spatial_size=(-1,self.size_y),\n",
    "                mode=[\"bilinear\",\"nearest\"],\n",
    "                keys=['image','label']),\n",
    "            RandSpatialCropd(\n",
    "                roi_size=(self.size_x,self.size_y),\n",
    "                random_center=True,\n",
    "                random_size=False,\n",
    "                keys=['image','label']),\n",
    "            RandFlipd(prob=0.5, \n",
    "                spatial_axis=0,\n",
    "                keys=['image', 'label']),\n",
    "            ToTensord(keys=[\"image\", \"label\"]),\n",
    "            ] )\n",
    "        \n",
    "        self.val_transforms = Compose(\n",
    "            [\n",
    "            LoadImaged(keys=[\"image\", \"label\"]),\n",
    "            AsChannelFirstd(keys='image'),\n",
    "            AsChannelFirstd(keys='label'),\n",
    "            ScaleIntensityRanged(\n",
    "                a_min=0, a_max=255,\n",
    "                b_min=0.0, b_max=1.0,\n",
    "                keys=[\"image\"]),\n",
    "            ARGUS_RandSpatialCropSlicesd(\n",
    "                num_slices=[self.num_slices,1],\n",
    "                center_slice=-self.num_slices/2 - 1,\n",
    "                axis=0,\n",
    "                reduce_to_statistics=[True,False],\n",
    "                extended=False,\n",
    "                include_center_slice=True,\n",
    "                include_gradient=True,\n",
    "                keys=['image','label']),\n",
    "            Resized(\n",
    "                spatial_size=(-1,self.size_y),\n",
    "                mode=[\"bilinear\",\"nearest\"],\n",
    "                keys=['image','label'])\n",
    "            ] )\n",
    "\n",
    "        self.device = torch.device(\"cuda:\"+str(self.device_num))\n",
    "\n",
    "    def setup_vfold(self, vfold_num):\n",
    "        train_ds = CacheDataset(data=self.train_files[vfold_num],\n",
    "            transform=self.train_transforms,\n",
    "            cache_rate=0.1,\n",
    "            num_workers=self.num_workers_train)\n",
    "        self.train_loader = DataLoader(train_ds,\n",
    "            batch_size=self.batch_size_train,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers_train)\n",
    "\n",
    "        val_ds = CacheDataset(data=self.val_files[vfold_num],\n",
    "            transform=self.val_transforms,\n",
    "            cache_rate=0.1,\n",
    "            num_workers=self.num_workers_val)\n",
    "        self.val_loader = DataLoader(val_ds,\n",
    "            batch_size=self.batch_size_val,\n",
    "            num_workers=self.num_workers_val)\n",
    "\n",
    "    def train_network_vfold(self, vfold_num):\n",
    "        self.model = UNet(\n",
    "            dimensions=self.net_dims,\n",
    "            in_channels=self.net_in_channels,\n",
    "            out_channels=self.num_classes,\n",
    "            channels=self.net_channels,\n",
    "            strides=self.net_strides,\n",
    "            num_res_units=2,\n",
    "            norm=Norm.BATCH,\n",
    "            ).to(self.device)\n",
    "        loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), 1e-4)\n",
    "        dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "\n",
    "        val_interval = 2\n",
    "\n",
    "        self.best_metric = -1\n",
    "        self.best_metric_epoch = -1\n",
    "        self.epoch_loss_values = []\n",
    "        self.metric_values = []\n",
    "\n",
    "        post_pred = Compose([EnsureType(),\n",
    "            AsDiscrete(argmax=True, to_onehot=True, num_classes=self.num_classes)])\n",
    "        post_label = Compose([EnsureType(),\n",
    "            AsDiscrete(to_onehot=True, num_classes=self.num_classes)])\n",
    "\n",
    "        for epoch in range(self.max_epochs):\n",
    "            print(\"-\" * 10)\n",
    "            print(f\"{vfold_num}: epoch {epoch + 1}/{self.max_epochs}\")\n",
    "            self.model.train()\n",
    "            epoch_loss = 0\n",
    "            step = 0\n",
    "            for batch_data in self.train_loader:\n",
    "                step += 1\n",
    "                inputs, labels = ( batch_data[\"image\"], batch_data[\"label\"] )\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "                print(f\"{step}/{len(self.train_files[vfold_num]) // self.train_loader.batch_size}, \"\n",
    "                      f\"train_loss: {loss.item():.4f}\")\n",
    "            epoch_loss /= step\n",
    "            self.epoch_loss_values.append(epoch_loss)\n",
    "            print(f\"{vfold_num} epoch {epoch+1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "            if (epoch + 1) % val_interval == 0:\n",
    "                self.model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for val_data in self.val_loader:\n",
    "                        val_inputs, val_labels = ( val_data[\"image\"], val_data[\"label\"] )\n",
    "                        val_inputs = val_inputs.to(self.device)\n",
    "                        val_labels = val_labels.to(self.device)\n",
    "                        roi_size = (self.size_x, self.size_y)\n",
    "                        sw_batch_size = self.batch_size_val\n",
    "                        val_outputs = sliding_window_inference(\n",
    "                           val_inputs, roi_size, sw_batch_size, self.model)\n",
    "                        # val_outputs = model(val_inputs)\n",
    "                        val_outputs = [post_pred(i) for i in\n",
    "                            decollate_batch(val_outputs)]\n",
    "                        val_labels = [post_label(i) for i in\n",
    "                            decollate_batch(val_labels)]\n",
    "                        # compute metric for current iteration\n",
    "                        dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "                    # aggregate the final mean dice result\n",
    "                    metric = dice_metric.aggregate().item()\n",
    "                    # reset the status for next validation round\n",
    "                    dice_metric.reset()\n",
    "\n",
    "                    self.metric_values.append(metric)\n",
    "                    if epoch > 100:\n",
    "                        metric = (self.metric_values[-1]+\n",
    "                            self.metric_values[-2]+\n",
    "                            self.metric_values[-3])/3\n",
    "                        if metric > self.best_metric:\n",
    "                            self.best_metric = metric\n",
    "                            self.best_metric_epoch = epoch + 1\n",
    "                            torch.save(self.model.state_dict(),\n",
    "                                self.model_filename_base+\n",
    "                                'best_model.vfold_'+\n",
    "                                str(vfold_num)+'.pth')\n",
    "                            print(\"saved new best metric model\")\n",
    "                    print( f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                           f\"\\nbest mean dice: {self.best_metric:.4f} \"\n",
    "                           f\"at epoch: {self.best_metric_epoch}\")\n",
    "                    torch.save(self.model.state_dict(),\n",
    "                        self.model_filename_base+'last_model.vfold_'+\n",
    "                        str(vfold_num)+'.pth')\n",
    "        np.save(self.model_filename_base+\"loss_\"+str(vfold_num)+\".npy\",\n",
    "            self.epoch_loss_values)\n",
    "        np.save(self.model_filename_base+\"val_dice_\"+str(vfold_num)+\".npy\",\n",
    "            self.metric_values)\n",
    "               \n",
    "    def view_image(self, image_num):\n",
    "        img_name=self.all_images[image_num]\n",
    "        print(img_name)\n",
    "        img = itk.imread(img_name)\n",
    "        lbl = itk.imread(self.all_labels[image_num])\n",
    "        num_plots = 5\n",
    "        num_slices = img.shape[0]\n",
    "        step_slices = num_slices / num_plots\n",
    "        for s in range(num_plots):\n",
    "            slice_num = int(step_slices*s)\n",
    "            plt.subplot(2,num_plots,s+1)\n",
    "            plt.imshow(img[slice_num,:,:])\n",
    "            plt.subplot(2,num_plots,num_plots+s+1)\n",
    "            plt.imshow(lbl[slice_num,:,:])\n",
    "            \n",
    "    def view_vfold_training_batch(self, vfold_num, batch_num):\n",
    "        for count,batch_data in enumerate(self.train_loader):\n",
    "            if count == batch_num:\n",
    "                inputs, labels = ( batch_data[\"image\"], batch_data[\"label\"] )\n",
    "                num_images = inputs.shape[0]\n",
    "                plt.figure(figsize=[30,30])\n",
    "                for i in range(num_images):\n",
    "                    img = inputs[i]\n",
    "                    lbl = labels[i]\n",
    "                    num_channels = img.shape[0]\n",
    "                    for c in range(num_channels):\n",
    "                        plt.subplot(num_images,num_channels+1,i*(num_channels+1)+c+1)\n",
    "                        plt.imshow(img[c,:,:])\n",
    "                    plt.subplot(num_images,num_channels+1,i*(num_channels+1)+num_channels+1)\n",
    "                    plt.imshow(lbl[0,:,:])\n",
    "                break\n",
    "                \n",
    "    def run_all(self):\n",
    "        self.setup_data_files()\n",
    "        self.setup_data_transforms()\n",
    "        for i in range(0,self.num_folds):\n",
    "            self.setup_vfold(i)\n",
    "            self.train_network_vfold(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c020044b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.24485379178077 gibibyte\n",
      "0.021044844761490822 gibibyte\n"
     ]
    }
   ],
   "source": [
    "img_dir = \"../../Data_PNB/Preprocessed\"\n",
    "anno_dir = \"../../Data_PNB/annotations/Sean_May22_CLEANED\"\n",
    "\n",
    "myNetwork = pocus_ai_network(img_dir, anno_dir,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "99e61a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num images / labels = 30 30\n",
      "0 [[' 11'], [' 57']]\n",
      "1 [[' 46'], [' 136']]\n",
      "2 [[' 207'], [' 179']]\n",
      "3 [[' 67'], [' 189']]\n",
      "4 [[' 93'], [' 204']]\n",
      "5 [[' 94'], [' 205']]\n",
      "6 [[' 134'], [' 211'], [' 217']]\n",
      "7 [[' 222A'], [' 238'], [' 39']]\n",
      "8 [[' 153'], [' 240'], [' 230']]\n",
      "9 [[' 193'], [' 54'], [' 191']]\n",
      "20 7 3\n",
      "22 6 2\n",
      "23 5 2\n",
      "24 4 2\n",
      "23 4 3\n",
      "23 5 2\n",
      "22 5 3\n",
      "19 5 6\n",
      "17 9 4\n",
      "17 10 3\n"
     ]
    }
   ],
   "source": [
    "myNetwork.setup_data_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c7e4bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#myNetwork.view_image(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8fe0f4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "myNetwork.setup_data_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "27dbb75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "myNetwork.setup_vfold(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9b88c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#myNetwork.view_vfold_training_batch(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0af8b3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "0: epoch 1/1500\n",
      "1/1, train_loss: 0.8241\n",
      "2/1, train_loss: 0.8270\n",
      "0 epoch 1 average loss: 0.8255\n",
      "----------\n",
      "0: epoch 2/1500\n",
      "1/1, train_loss: 0.8217\n",
      "2/1, train_loss: 0.8292\n",
      "0 epoch 2 average loss: 0.8255\n",
      "current epoch: 2 current mean dice: 0.0338\n",
      "best mean dice: -1.0000 at epoch: -1\n",
      "----------\n",
      "0: epoch 3/1500\n",
      "1/1, train_loss: 0.8254\n",
      "2/1, train_loss: 0.8182\n",
      "0 epoch 3 average loss: 0.8218\n",
      "----------\n",
      "0: epoch 4/1500\n",
      "1/1, train_loss: 0.8168\n",
      "2/1, train_loss: 0.8186\n",
      "0 epoch 4 average loss: 0.8177\n",
      "current epoch: 4 current mean dice: 0.0205\n",
      "best mean dice: -1.0000 at epoch: -1\n",
      "----------\n",
      "0: epoch 5/1500\n",
      "1/1, train_loss: 0.8139\n",
      "2/1, train_loss: 0.8177\n",
      "0 epoch 5 average loss: 0.8158\n",
      "----------\n",
      "0: epoch 6/1500\n",
      "1/1, train_loss: 0.8124\n",
      "2/1, train_loss: 0.8120\n",
      "0 epoch 6 average loss: 0.8122\n",
      "current epoch: 6 current mean dice: 0.0233\n",
      "best mean dice: -1.0000 at epoch: -1\n",
      "----------\n",
      "0: epoch 7/1500\n",
      "1/1, train_loss: 0.8094\n",
      "2/1, train_loss: 0.8102\n",
      "0 epoch 7 average loss: 0.8098\n",
      "----------\n",
      "0: epoch 8/1500\n",
      "1/1, train_loss: 0.8158\n",
      "2/1, train_loss: 0.8081\n",
      "0 epoch 8 average loss: 0.8120\n",
      "current epoch: 8 current mean dice: 0.0279\n",
      "best mean dice: -1.0000 at epoch: -1\n",
      "----------\n",
      "0: epoch 9/1500\n",
      "1/1, train_loss: 0.8051\n",
      "2/1, train_loss: 0.8133\n",
      "0 epoch 9 average loss: 0.8092\n",
      "----------\n",
      "0: epoch 10/1500\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmyNetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_network_vfold\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36mpocus_ai_network.train_network_vfold\u001b[1;34m(self, vfold_num)\u001b[0m\n\u001b[0;32m    294\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    295\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader:\n\u001b[0;32m    297\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    298\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m ( batch_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m], batch_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m] )\n",
      "File \u001b[1;32mc:\\src\\venv_pip_monai\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:368\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\src\\venv_pip_monai\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:314\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\src\\venv_pip_monai\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:927\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    920\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m--> 927\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument"
     ]
    }
   ],
   "source": [
    "myNetwork.train_network_vfold(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e960fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
